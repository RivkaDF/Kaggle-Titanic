{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "5              6         0       3   \n",
      "6              7         0       1   \n",
      "7              8         0       3   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "12            13         0       3   \n",
      "13            14         0       3   \n",
      "14            15         0       3   \n",
      "15            16         1       2   \n",
      "16            17         0       3   \n",
      "17            18         1       2   \n",
      "18            19         0       3   \n",
      "19            20         1       3   \n",
      "20            21         0       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "24            25         0       3   \n",
      "25            26         1       3   \n",
      "26            27         0       3   \n",
      "27            28         0       1   \n",
      "28            29         1       3   \n",
      "29            30         0       3   \n",
      "..           ...       ...     ...   \n",
      "861          862         0       2   \n",
      "862          863         1       1   \n",
      "863          864         0       3   \n",
      "864          865         0       2   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "867          868         0       1   \n",
      "868          869         0       3   \n",
      "869          870         1       3   \n",
      "870          871         0       3   \n",
      "871          872         1       1   \n",
      "872          873         0       1   \n",
      "873          874         0       3   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "876          877         0       3   \n",
      "877          878         0       3   \n",
      "878          879         0       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "881          882         0       3   \n",
      "882          883         0       3   \n",
      "883          884         0       2   \n",
      "884          885         0       3   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name  Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    0  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina    1  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1   \n",
      "4                             Allen, Mr. William Henry    0  35.0      0   \n",
      "5                                     Moran, Mr. James    0   NaN      0   \n",
      "6                              McCarthy, Mr. Timothy J    0  54.0      0   \n",
      "7                       Palsson, Master. Gosta Leonard    0   2.0      3   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    1  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)    1  14.0      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut    1   4.0      1   \n",
      "11                            Bonnell, Miss. Elizabeth    1  58.0      0   \n",
      "12                      Saundercock, Mr. William Henry    0  20.0      0   \n",
      "13                         Andersson, Mr. Anders Johan    0  39.0      1   \n",
      "14                Vestrom, Miss. Hulda Amanda Adolfina    1  14.0      0   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)     1  55.0      0   \n",
      "16                                Rice, Master. Eugene    0   2.0      4   \n",
      "17                        Williams, Mr. Charles Eugene    0   NaN      0   \n",
      "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...    1  31.0      1   \n",
      "19                             Masselmani, Mrs. Fatima    1   NaN      0   \n",
      "20                                Fynney, Mr. Joseph J    0  35.0      0   \n",
      "21                               Beesley, Mr. Lawrence    0  34.0      0   \n",
      "22                         McGowan, Miss. Anna \"Annie\"    1  15.0      0   \n",
      "23                        Sloper, Mr. William Thompson    0  28.0      0   \n",
      "24                       Palsson, Miss. Torborg Danira    1   8.0      3   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...    1  38.0      1   \n",
      "26                             Emir, Mr. Farred Chehab    0   NaN      0   \n",
      "27                      Fortune, Mr. Charles Alexander    0  19.0      3   \n",
      "28                       O'Dwyer, Miss. Ellen \"Nellie\"    1   NaN      0   \n",
      "29                                 Todoroff, Mr. Lalio    0   NaN      0   \n",
      "..                                                 ...  ...   ...    ...   \n",
      "861                        Giles, Mr. Frederick Edward    0  21.0      1   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...    1  48.0      0   \n",
      "863                  Sage, Miss. Dorothy Edith \"Dolly\"    1   NaN      8   \n",
      "864                             Gill, Mr. John William    0  24.0      0   \n",
      "865                           Bystrom, Mrs. (Karolina)    1  42.0      0   \n",
      "866                       Duran y More, Miss. Asuncion    1  27.0      1   \n",
      "867               Roebling, Mr. Washington Augustus II    0  31.0      0   \n",
      "868                        van Melkebeke, Mr. Philemon    0   NaN      0   \n",
      "869                    Johnson, Master. Harold Theodor    0   4.0      1   \n",
      "870                                  Balkic, Mr. Cerin    0  26.0      0   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)    1  47.0      1   \n",
      "872                           Carlsson, Mr. Frans Olof    0  33.0      0   \n",
      "873                        Vander Cruyssen, Mr. Victor    0  47.0      0   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)    1  28.0      1   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"    1  15.0      0   \n",
      "876                      Gustafsson, Mr. Alfred Ossian    0  20.0      0   \n",
      "877                               Petroff, Mr. Nedelio    0  19.0      0   \n",
      "878                                 Laleff, Mr. Kristo    0   NaN      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)    1  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)    1  25.0      0   \n",
      "881                                 Markun, Mr. Johann    0  33.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika    1  22.0      0   \n",
      "883                      Banfield, Mr. Frederick James    0  28.0      0   \n",
      "884                             Sutehall, Mr. Henry Jr    0  25.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)    1  39.0      0   \n",
      "886                              Montvila, Rev. Juozas    0  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith    1  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"    1   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    0  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    0  32.0      0   \n",
      "\n",
      "     Parch            Ticket      Fare        Cabin Embarked  \n",
      "0        0         A/5 21171    7.2500          NaN        S  \n",
      "1        0          PC 17599   71.2833          C85        C  \n",
      "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
      "3        0            113803   53.1000         C123        S  \n",
      "4        0            373450    8.0500          NaN        S  \n",
      "5        0            330877    8.4583          NaN        Q  \n",
      "6        0             17463   51.8625          E46        S  \n",
      "7        1            349909   21.0750          NaN        S  \n",
      "8        2            347742   11.1333          NaN        S  \n",
      "9        0            237736   30.0708          NaN        C  \n",
      "10       1           PP 9549   16.7000           G6        S  \n",
      "11       0            113783   26.5500         C103        S  \n",
      "12       0         A/5. 2151    8.0500          NaN        S  \n",
      "13       5            347082   31.2750          NaN        S  \n",
      "14       0            350406    7.8542          NaN        S  \n",
      "15       0            248706   16.0000          NaN        S  \n",
      "16       1            382652   29.1250          NaN        Q  \n",
      "17       0            244373   13.0000          NaN        S  \n",
      "18       0            345763   18.0000          NaN        S  \n",
      "19       0              2649    7.2250          NaN        C  \n",
      "20       0            239865   26.0000          NaN        S  \n",
      "21       0            248698   13.0000          D56        S  \n",
      "22       0            330923    8.0292          NaN        Q  \n",
      "23       0            113788   35.5000           A6        S  \n",
      "24       1            349909   21.0750          NaN        S  \n",
      "25       5            347077   31.3875          NaN        S  \n",
      "26       0              2631    7.2250          NaN        C  \n",
      "27       2             19950  263.0000  C23 C25 C27        S  \n",
      "28       0            330959    7.8792          NaN        Q  \n",
      "29       0            349216    7.8958          NaN        S  \n",
      "..     ...               ...       ...          ...      ...  \n",
      "861      0             28134   11.5000          NaN        S  \n",
      "862      0             17466   25.9292          D17        S  \n",
      "863      2          CA. 2343   69.5500          NaN        S  \n",
      "864      0            233866   13.0000          NaN        S  \n",
      "865      0            236852   13.0000          NaN        S  \n",
      "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
      "867      0          PC 17590   50.4958          A24        S  \n",
      "868      0            345777    9.5000          NaN        S  \n",
      "869      1            347742   11.1333          NaN        S  \n",
      "870      0            349248    7.8958          NaN        S  \n",
      "871      1             11751   52.5542          D35        S  \n",
      "872      0               695    5.0000  B51 B53 B55        S  \n",
      "873      0            345765    9.0000          NaN        S  \n",
      "874      0         P/PP 3381   24.0000          NaN        C  \n",
      "875      0              2667    7.2250          NaN        C  \n",
      "876      0              7534    9.8458          NaN        S  \n",
      "877      0            349212    7.8958          NaN        S  \n",
      "878      0            349217    7.8958          NaN        S  \n",
      "879      1             11767   83.1583          C50        C  \n",
      "880      1            230433   26.0000          NaN        S  \n",
      "881      0            349257    7.8958          NaN        S  \n",
      "882      0              7552   10.5167          NaN        S  \n",
      "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
      "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
      "885      5            382652   29.1250          NaN        Q  \n",
      "886      0            211536   13.0000          NaN        S  \n",
      "887      0            112053   30.0000          B42        S  \n",
      "888      2        W./C. 6607   23.4500          NaN        S  \n",
      "889      0            111369   30.0000         C148        C  \n",
      "890      0            370376    7.7500          NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "#import data\n",
    "train_data = pd.read_csv ('train.csv')\n",
    "test_data = pd.read_csv ('test.csv')\n",
    "\n",
    "#convert Sex values to 0 for Male and 1 for Female\n",
    "train_data[['Sex']] = (train_data[['Sex']].apply(lambda x: pd.factorize(x)[0]))\n",
    "test_data[['Sex']] = (train_data[['Sex']].apply(lambda x: pd.factorize(x)[0]))\n",
    "\n",
    "#Convert below features to be categorical\n",
    "\n",
    "train_data['Sex'] = pd.Categorical(train_data.Sex).codes\n",
    "\n",
    "print (train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Age'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    30.626179\n",
       "1    28.343690\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Age is important \n",
    "train_data.groupby('Survived')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  FamSz\n",
       "0         1        374\n",
       "          2         72\n",
       "          3         43\n",
       "          6         19\n",
       "          5         12\n",
       "          4          8\n",
       "          7          8\n",
       "          11         7\n",
       "          8          6\n",
       "1         1        163\n",
       "          2         89\n",
       "          3         59\n",
       "          4         21\n",
       "          7          4\n",
       "          5          3\n",
       "          6          3\n",
       "Name: FamSz, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new feature FamSz for Family Size \n",
    "\n",
    "train_data['FamSz'] = train_data['Parch'] + train_data['SibSp'] + 1\n",
    "test_data['FamSz'] = test_data['Parch'] + train_data['SibSp'] + 1\n",
    "train_data.groupby('Survived')['FamSz'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['CatFare']= pd.qcut(train_data.Fare, q=4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  Sex  SibSp  Parch      Fare  FamSz  \\\n",
      "0              1         0       3    0      1      0    7.2500      2   \n",
      "1              2         1       1    1      1      0   71.2833      2   \n",
      "2              3         1       3    1      0      0    7.9250      1   \n",
      "3              4         1       1    1      1      0   53.1000      2   \n",
      "4              5         0       3    0      0      0    8.0500      1   \n",
      "5              6         0       3    0      0      0    8.4583      1   \n",
      "6              7         0       1    0      0      0   51.8625      1   \n",
      "7              8         0       3    0      3      1   21.0750      5   \n",
      "8              9         1       3    1      0      2   11.1333      3   \n",
      "9             10         1       2    1      1      0   30.0708      2   \n",
      "10            11         1       3    1      1      1   16.7000      3   \n",
      "11            12         1       1    1      0      0   26.5500      1   \n",
      "12            13         0       3    0      0      0    8.0500      1   \n",
      "13            14         0       3    0      1      5   31.2750      7   \n",
      "14            15         0       3    1      0      0    7.8542      1   \n",
      "15            16         1       2    1      0      0   16.0000      1   \n",
      "16            17         0       3    0      4      1   29.1250      6   \n",
      "17            18         1       2    0      0      0   13.0000      1   \n",
      "18            19         0       3    1      1      0   18.0000      2   \n",
      "19            20         1       3    1      0      0    7.2250      1   \n",
      "20            21         0       2    0      0      0   26.0000      1   \n",
      "21            22         1       2    0      0      0   13.0000      1   \n",
      "22            23         1       3    1      0      0    8.0292      1   \n",
      "23            24         1       1    0      0      0   35.5000      1   \n",
      "24            25         0       3    1      3      1   21.0750      5   \n",
      "25            26         1       3    1      1      5   31.3875      7   \n",
      "26            27         0       3    0      0      0    7.2250      1   \n",
      "27            28         0       1    0      3      2  263.0000      6   \n",
      "28            29         1       3    1      0      0    7.8792      1   \n",
      "29            30         0       3    0      0      0    7.8958      1   \n",
      "..           ...       ...     ...  ...    ...    ...       ...    ...   \n",
      "861          862         0       2    0      1      0   11.5000      2   \n",
      "862          863         1       1    1      0      0   25.9292      1   \n",
      "863          864         0       3    1      8      2   69.5500     11   \n",
      "864          865         0       2    0      0      0   13.0000      1   \n",
      "865          866         1       2    1      0      0   13.0000      1   \n",
      "866          867         1       2    1      1      0   13.8583      2   \n",
      "867          868         0       1    0      0      0   50.4958      1   \n",
      "868          869         0       3    0      0      0    9.5000      1   \n",
      "869          870         1       3    0      1      1   11.1333      3   \n",
      "870          871         0       3    0      0      0    7.8958      1   \n",
      "871          872         1       1    1      1      1   52.5542      3   \n",
      "872          873         0       1    0      0      0    5.0000      1   \n",
      "873          874         0       3    0      0      0    9.0000      1   \n",
      "874          875         1       2    1      1      0   24.0000      2   \n",
      "875          876         1       3    1      0      0    7.2250      1   \n",
      "876          877         0       3    0      0      0    9.8458      1   \n",
      "877          878         0       3    0      0      0    7.8958      1   \n",
      "878          879         0       3    0      0      0    7.8958      1   \n",
      "879          880         1       1    1      0      1   83.1583      2   \n",
      "880          881         1       2    1      0      1   26.0000      2   \n",
      "881          882         0       3    0      0      0    7.8958      1   \n",
      "882          883         0       3    1      0      0   10.5167      1   \n",
      "883          884         0       2    0      0      0   10.5000      1   \n",
      "884          885         0       3    0      0      0    7.0500      1   \n",
      "885          886         0       3    1      0      5   29.1250      6   \n",
      "886          887         0       2    0      0      0   13.0000      1   \n",
      "887          888         1       1    1      0      0   30.0000      1   \n",
      "888          889         0       3    1      1      2   23.4500      4   \n",
      "889          890         1       1    0      0      0   30.0000      1   \n",
      "890          891         0       3    0      0      0    7.7500      1   \n",
      "\n",
      "     CatFare  \n",
      "0          0  \n",
      "1          3  \n",
      "2          1  \n",
      "3          3  \n",
      "4          1  \n",
      "5          1  \n",
      "6          3  \n",
      "7          2  \n",
      "8          1  \n",
      "9          2  \n",
      "10         2  \n",
      "11         2  \n",
      "12         1  \n",
      "13         3  \n",
      "14         0  \n",
      "15         2  \n",
      "16         2  \n",
      "17         1  \n",
      "18         2  \n",
      "19         0  \n",
      "20         2  \n",
      "21         1  \n",
      "22         1  \n",
      "23         3  \n",
      "24         2  \n",
      "25         3  \n",
      "26         0  \n",
      "27         3  \n",
      "28         0  \n",
      "29         0  \n",
      "..       ...  \n",
      "861        1  \n",
      "862        2  \n",
      "863        3  \n",
      "864        1  \n",
      "865        1  \n",
      "866        1  \n",
      "867        3  \n",
      "868        1  \n",
      "869        1  \n",
      "870        0  \n",
      "871        3  \n",
      "872        0  \n",
      "873        1  \n",
      "874        2  \n",
      "875        0  \n",
      "876        1  \n",
      "877        0  \n",
      "878        0  \n",
      "879        3  \n",
      "880        2  \n",
      "881        0  \n",
      "882        1  \n",
      "883        1  \n",
      "884        0  \n",
      "885        2  \n",
      "886        1  \n",
      "887        2  \n",
      "888        2  \n",
      "889        2  \n",
      "890        0  \n",
      "\n",
      "[891 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop columns we won't be using\n",
    "\n",
    "train_data = train_data.drop(['Name', 'Ticket','Cabin', 'Embarked', 'Age'], axis = 1)\n",
    "test_data = test_data.drop(['Name', 'Ticket', 'Cabin', 'Embarked', 'Age'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "FamSz          0\n",
      "CatFare        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Find which of the remaining features show nulls\n",
    "\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Repalace all NaN with 0 - assuming Passengers with missing ages are babies\n",
    "\n",
    "#train_data['Age'] = train_data['Age'].fillna(0)\n",
    "#test_data['Age'] = test_data['Age'].fillna(0)\n",
    "\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a new feature 'Status' from the 'Names' column\n",
    "\n",
    "train_data['Status'] = np.nan\n",
    "train_data['Status'][train_data.Name.str.contains('Mr.')] = 'Mr'\n",
    "train_data['Status'][train_data.Name.str.contains('Mrs.')] = 'Mrs'\n",
    "train_data['Status'][train_data.Name.str.contains('Miss.')] = 'Miss'\n",
    "train_data['Status'][train_data.Name.str.contains('Master.')] = 'Master'\n",
    "train_data['Status'][train_data.Name.str.contains('Rev.')] = 'Rev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data['Survived'] = pd.Categorical(train_data.Survived).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select features and target for our classifier\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Fare']\n",
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View first 5 rows of features data\n",
    "train_data[features].head()\n",
    "\n",
    "#View first 5 rows of target data\n",
    "\n",
    "train_data[target].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a cross validation set\n",
    "[train_data_tr, train_data_cv] = train_test_split(train_data, test_size = .25, random_state = 42)\n",
    "\n",
    "Xtr = train_data_tr[features]\n",
    "Ytr = train_data_tr[target]\n",
    "Xtrcv = train_data_cv[features]\n",
    "Ytrcv = train_data_cv[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the decision tree with default parameters\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#Fit Decision Tree to our training features target values\n",
    "clf.fit(Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12868961,  0.39577367,  0.47553671])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Feature Importance\n",
    "\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make predictions using the train data features\n",
    "\n",
    "predictions = clf.predict(Xtrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820627802690583"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Accuracy of our Predictions on the Train Data\n",
    "\n",
    "accuracy = accuracy_score(Ytrcv, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82513888888888887"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do CV with 100 folds\n",
    "\n",
    "scores = cross_val_score(clf, train_data[features], train_data[target], cv = 100, scoring = 'accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's try with Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(Xtr,Ytr)\n",
    "lr_predictions = lr.predict(Xtrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77130044843049328"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check accuracy for the Logistic Regression model as well\n",
    "\n",
    "lr_accuracy = accuracy_score(Ytrcv, lr_predictions)\n",
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7810555555555555"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do CV  with 100 folds for Logistic Regression\n",
    "\n",
    "scores = cross_val_score(lr, train_data[features], train_data[target], cv = 100, scoring = 'accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
